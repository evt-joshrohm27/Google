// Copyright 2022 Google LLC
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//      http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

// This API is experimental and under-development.

syntax = "proto3";

package sax.server.lm;

import "saxml/protobuf/common.proto";

// Usage:
//
//   score_req = ScoreRequest(model_key="lm1t",
//                            suffix="some text",
//                            prefix="optional suffix")
//   score_response = lm_service.Score(score_req)
//   print(score_response.logp)
//
//   sample_req = GenerateRequest(model_key="lm1t",
//                                text="some prefix text",
//                                extra_inputs=ExtraInputs(
//                                  items={temperature: 0.1}),
//                               )
//   score_response = lm_service.Generate(sample_req)
//   print(sample_req.texts[0].text, sample_req.texts[0].score)

message ScoreRequest {
  string model_key = 1;
  repeated string suffix = 2;
  // If `prefix` is not empty, it will be prepended to `suffix`, but the score
  // will be calculated only on `suffix`.
  string prefix = 3;
  .sax.ExtraInputs extra_inputs = 4;
}

message ScoreResponse {
  repeated double logp = 1;
}

message GenerateRequest {
  string model_key = 1;
  // The prefix text.
  string text = 2;
  .sax.ExtraInputs extra_inputs = 3;
}

message DecodedText {
  // The decoded text. Depending on the servable model params, the result may or
  // may not include the input prefix text in SamplingDecodeRequest. See
  // DecodeHParams in servable_lm_model_param.py.
  string text = 1;
  double score = 2;
}

message GenerateResponse {
  repeated DecodedText texts = 1;
}

// Usage example:
//
// results = [""] * num_of_samples
// scores = [0.0] * num_of_samples
// for response in range(get_streaming_responses()):
//   for i, item in enumerate(response.items):
//     results[i] = results[i][:item.prefix_len] + item.text
//     scores[i] = item.score
//
// results[i] and scores[i] will contain the fully decoded text and score for
// the ith item.
message GenerateStreamItem {
  // The decoded text. This contains new, incrementally decoded text not
  // included in the result accumulated so far.
  string text = 1;

  // How many leading characters in the result accumulated so far should
  // prefix the `text` field above.
  int32 prefix_len = 2;

  // The final response in a stream is required to contain scores for each
  // fully decoded item.
  double score = 3;
}

// Each response message represents one incremental decoding result in a
// streaming of results.
message GenerateStreamResponse {
  // Each item corresponds to one of several possible decoded suffixes.
  // The server decides on the order of these items. In other words, the order
  // is not guaranteed to be stable between responses.
  repeated GenerateStreamItem items = 1;
}

message EmbedRequest {
  string model_key = 1;
  string text = 2;
  .sax.ExtraInputs extra_inputs = 3;
}

message EmbedResponse {
  repeated double embedding = 1 [packed = true];
}

service LMService {
  // Returns the score (e.g., log pplx) given the text.
  rpc Score(ScoreRequest) returns (ScoreResponse);

  // Returns generated texts using the text prefix in the request.
  rpc Generate(GenerateRequest) returns (GenerateResponse);

  // Returns a stream of generated texts using the text prefix in the request.
  rpc GenerateStream(GenerateRequest) returns (stream GenerateStreamResponse);

  // Returns a text embedding given the text.
  rpc Embed(EmbedRequest) returns (EmbedResponse);
}
